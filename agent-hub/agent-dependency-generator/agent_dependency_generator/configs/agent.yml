agent:
  pyproject_prompt: |
    **C: Context**  
    We need to automate generation of Poetry-compatible Python packages that strictly follow:  
    1. User-provided naming conventions (`agent_name`/`module_name`)  
    2. Dependency autodetection from code analysis  
    3. MIT-licensed open source structure  
    
    **O: Objective**  
    Create a perfect `pyproject.toml` that:  
    - 100% preserves user's `agent_name` (hyphenated) and `module_name` (underscored)  
    - Automatically adds dependencies like `requests` for HTTP calls  
    - Contains REQUIRED Poetry scripts/config sections  
    
    **S: Style**  
    Technical precision with:  
    - TOML syntax validation  
    - Named parameter interpolation (`{agent_name}`, `module_name`)  
    - Dependency fingerprints (code pattern → package mapping)  
    
    **T: Tone**  
    Authoritative yet adaptable:  
    - Error codes for invalid inputs (400/401/402)  
    - Clear package structure enforcement  
    - Strict no-hallucination policy for names  
    
    **A: Audience**  
    Python developers needing:  
    - Poetry packaging automation  
    - Dependency management  
    - CI/CD-ready configurations  
    
    **R: Response Format**  
    ```toml
    # STRICT TEMPLATE - NO DEVIATIONS
    [tool.poetry]
    name = "{agent_name}"
    version = "0.1.0"
    description = "Auto-generated agent package"
    authors = [
        "Mofa Bot <mofa-bot@moxin.com>",
        "Technical Owner <eng@moxin.com>"
    ]
    packages = [{ include = "{module_name}" }] # ⟨⟨critical⟩⟩ MUST PRESERVE USER INPUT
    
    [tool.poetry.dependencies]
    python = ">=3.10"
    pyarrow = ">= 5.0.0"
    # ⟨⟨auto⟩⟩ Detected from code patterns:
    # requests.get → requests = "*"
    
    [tool.poetry.scripts]
    {agent_name} = "{module_name}.main:main" # ⟨⟨unmodified⟩⟩ EXACT USER VALUES
    
    [build-system]
    requires = ["poetry-core>=1.8.0"]
    build-backend = "poetry.core.masonry.api"
    ```
    
    **Validation Triggers**  
     If `packages` doesn't EXACTLY match user's `module_name` → 401 error  
     If scripts section alters naming conventions → Full regeneration  
     Must pass `tomlkit.parse()` validation  
    
    **Examples**
    agent_name: UniversityFinder
    module_name: find_universities
    ```toml
    [tool.poetry]
    name = "UniversityFinder"
    version = "0.1.0"
    description = "Auto-generated agent package"
    authors = [
        "AI Mofa Bot Generator <mofa-bot@moxin.com>",
    ]
    packages = [{ include = "find_universities" }]
    
    [tool.poetry.dependencies]
    python = ">=3.10"
    requests = "*"
    
    [tool.poetry.scripts]
    UniversityFinder = "find_universities.main:main"
    
    [build-system]
    requires = ["poetry-core>=1.8.0"]
    build-backend = "poetry.core.masonry.api"
    ```

  readme_prompt: |
  
    **C: Context**  
    You are given the implementation details for a Dora-rs node, including:  
    - `{{PROJECT_NAME}}` (crate name)  
    - High-level description of functionality (`{{DESCRIPTION}}`)  
    - Code excerpts (`{{CODE_SNIPPETS}}`) showing key structs, methods, calls to `receive_parameter`, `send_output`, `MofaAgent` implementations  
    - Dependency list (`{{DEPENDENCIES}}`) in Cargo.toml format  
  
    **O: Objective**  
    Generate a `README.md` with the exact structure below, filling in placeholders from the context:
  
    ```markdown
    # {{PROJECT_NAME}}
  
    {{TAGLINE}}
  
    ## Features
    - {{FEATURE_1}}
    - {{FEATURE_2}}
    - {{FEATURE_3}}
  
    ## Getting Started
  
    ### Installation
    Install via cargo:
    ```bash

    pip install -e .
    ````
    
    ## Basic Usage
    
    Create a YAML config (e.g., `demo.yml`):
    
    ```yaml
    {{YAML_CONFIG}}
    ```
    
    Run the demo:
    
    ```bash
    dora build demo.yml
    dora start demo.yml
    ```
    
    
    ## Integration with Other Nodes
    
    To connect with your existing node:
    
    ```yaml
    {{INTEGRATION_CONFIG}}
    ```
    
    Your point source must output:
    
    * Topic: `points_to_track`
    * Data: Flattened array of coordinates
    * Metadata:
    
      ```json
      {{METADATA_JSON}}
      ```
    
    ## API Reference
    
    ### Input Topics
    
    | Topic              | Type               | Description        |
    | ------------------ | ------------------ | ------------------ |
    | {{INPUT\_1\_NAME}} | {{INPUT\_1\_TYPE}} | {{INPUT\_1\_DESC}} |
    | {{INPUT\_2\_NAME}} | {{INPUT\_2\_TYPE}} | {{INPUT\_2\_DESC}} |
    
    ### Output Topics
    
    | Topic               | Type                | Description         |
    | ------------------- | ------------------- | ------------------- |
    | {{OUTPUT\_1\_NAME}} | {{OUTPUT\_1\_TYPE}} | {{OUTPUT\_1\_DESC}} |
    | {{OUTPUT\_2\_NAME}} | {{OUTPUT\_2\_TYPE}} | {{OUTPUT\_2\_DESC}} |
    

    
    ## License
    
    Released under the {{LICENSE}} License.
    
    ````
    
    **S: Style**
    - Sections and headings must match exactly.
    - Use markdown code blocks for commands, YAML, JSON, and code examples.
    - Bullet lists for features and demo steps.
    - Tables for input/output topics.
    
    **A: Audience**
    Dora-rs node developers and maintainers who need clear installation steps,  integration details, and API specifications.
    
    **T: Task**
    1. Replace all `{{PLACEHOLDER}}` entries with the provided context.  
    2. Ensure formatting and section order exactly follow the template.  
    3. If code contains `receive_parameter`, list each parameter under “Input Topics.”  
    4. If code contains `send_output`, list each output under “Output Topics.”
    5. If there are ≥3 distinct logical steps or modules in the code, generate a Mermaid flowchart under a new “Workflow” section **before** “Development”:
       ```mermaid
       flowchart LR
         {{MERMAID_NODES}}
         {{MERMAID_EDGES}}
       ```
    
    Examples:
      dora-cotracker
      A Dora node that implements real-time object tracking using Facebook's CoTracker model. The node supports both interactive point selection via clicking and programmatic point input through Dora's messaging system.
      
      Features
      Real-time object tracking using CoTracker
      Support for multiple tracking points
      Interactive point selection via mouse clicks
      Programmatic point input through Dora messages
      Visualization of tracked points with unique identifiers
      Getting Started
      Installation
      Install using uv:
      
      uv venv -p 3.11 --seed
      uv pip install -e .

      
      Setting up the node
      Interactive point selection
      Real-time tracking performance
      Basic Usage
      Create a YAML configuration file (e.g., demo.yml):
      nodes:
        - id: camera
          build: pip install opencv-video-capture
          path: opencv-video-capture
          inputs:
            tick: dora/timer/millis/100
          outputs:
            - image
          env:
            CAPTURE_PATH: "0"
            ENCODING: "rgb8"
            IMAGE_WIDTH: "640"
            IMAGE_HEIGHT: "480"
      
        - id: tracker
          build: pip install -e dora-cotracker
          path: dora-cotracker
          inputs:
            image: camera/image
            points_to_track: input/points_to_track
          outputs:
            - tracked_image
            - tracked_points
      
        - id: display
          build: pip install dora-rerun
          path: dora-rerun
          inputs:
            image: camera/image
            tracked_image: tracker/tracked_image
      Note - this only has the cv2 as an input source. see below to add your nodes workflow and pass points directly.
      
      Run the demo:
      dora build demo.yml      
      dora start demo.yml 
      
      Left-click to add tracking points
      Points will be tracked automatically across frames
      Each point is assigned a unique identifier (C0, C1, etc. for clicked points and I0, I1, etc for input points)
      2. Dynamic Point Integration
      The node can receive tracking points from other models or nodes in your pipeline. Common use cases include:
      
      Tracking YOLO detection centroids
      Following pose estimation keypoints
      Monitoring segmentation mask centers
      Custom object detection points
      example showing how to send tracking points through Dora messages using a custom input node:
      
      import numpy as np
      import pyarrow as pa
      from dora import Node
      
      class PointInputNode:
          def __init__(self):
              self.node = Node("point-input")
          
          def send_points(self, points):
              """
              Send points to tracker
              Args:
                  points: Nx2 array of (x,y) coordinates
              """
              points = np.array(points, dtype=np.float32)
              self.node.send_output(
                  "points_to_track",
                  pa.array(points.ravel()),
                  {
                      "num_points": len(points),
                      "dtype": "float32", 
                      "shape": (len(points), 2)
                  }
              )
      
          def run(self):
              # Example: Track 3 points
              points = np.array([
                  [320, 240],  # Center
                  [160, 120],  # Top-left
                  [480, 360]   # Bottom-right
              ])
              self.send_points(points)
      To connect your existing node that outputs tracking points with the CoTracker node, add the following to your YAML configuration:
      
      nodes:
        # Your existing point source node (e.g., YOLO detector, pose estimator, etc.)
        - id: point_source
          build: pip install your-node  # Replace with your node's name
          path: your-point-source-node  # Replace with your node's path
          inputs:
            image: camera/image  # If your node needs image input
          outputs:
            - points_to_track    # Must output points in required format
      
        # CoTracker node configuration
        - id: tracker
          build: pip install dora-cotracker
          path: dora-cotracker
          inputs:
            image: camera/image
            points_to_track: point_source/points_to_track  # Connect to your point source
          outputs:
            - tracked_image
            - tracked_points
      
        # Optional visualization
        - id: display
          build: pip install dora-rerun
          path: dora-rerun
          inputs:
            image: camera/image
            tracked_image: tracker/tracked_image
      Your point source node must output points in the following format:
      
      Topic name: points_to_track
      Data: Flattened numpy array of x,y coordinates
      Metadata:
      {
          "num_points": len(points),  # Number of points
          "dtype": "float32",        # Data type
          "shape": (N, 2)           # N points, 2 coordinates each
      }
      Example point source implementations:
      
      YOLO detection centroids
      Pose estimation keypoints
      Face landmark detectors
      Custom object detectors
      For dynamic updates, send new points whenever your source node processes a new frame. The tracker will maintain temporal consistency between updates. **
      
      API Reference
      Input Topics
      image: Input video stream (RGB format)
      points_to_track: Points to track
      Format: Flattened array of x,y coordinates
      Metadata:
      num_points: Number of points
      dtype: "float32"
      shape: (N, 2) where N is number of points
      Output Topics
      tracked_image: Visualization with tracked points
      tracked_points: Current positions of tracked points
      Same format as input points






    
    
