# 1，演讲者百科全书
#### **2025-04-28: 演讲者百科全书 - 信息收集与初步提取**
- **任务：**  
  - 提取演讲者的照片和基本传记信息（LLM文本提取）。  
  - 提取演讲者的关键词、姓名、组织、以及个人经历。
  - 查询rag对应的这个人的名称/信息以及相关的内容
- **目标：**  
  - 完成对演讲者的基础信息提取，并开始收集详细资料。  
- **输出：**  
  - 提取到的演讲者照片、传记、姓名、组织、以及基本经历等初步信息。

#### **2025-04-29: 演讲者百科全书 - 完整资料收集与验证**
- **任务：**  
  - 完成对演讲者homepage arxiv linkedin news blog youtube 等多渠道进行数据的收集。
  - 收集的工具大概是 firecrawl、selenium、serper、browser-use 等
  - 使用llm对每个不同的数据工具的结果进行整合
- **目标：**  
  - 完整的演讲者百科资料，包含论文、新闻、个人经历等内容。  
- **输出：**  
  - 完整的演讲者百科初稿。

#### **2025-04-30: 演讲者百科全书 - 完成与整合与优化**
- **任务：**  
  - 对第一部分内容进行总结和整理，确保资料的全面性与准确性。  
  - 完成演讲者百科的最终整合，包括所有收集的材料：论文、新闻、个人经历、媒体曝光等。
- **目标：**  
  - 完成最终的演讲者百科内容，并确保格式整洁。  
- **输出：**  
  - 完整的演讲者百科全书报告。

---


# 2，演讲内容分析

---



### **2025-05-02: 文本分段与主题分类**

#### **任务：**
1. **长文本分段：**
   - 根据演讲的结构或时间戳将长文本分成多个段落。使用LLM（如GPT）或简单规则进行段落分割，确保每个段落内容连贯且具有代表性。
   - **方法：** 如果转录文本较长，可以按语义或时间戳分割成较小的文本块，每个块不超过500-1000字。

2. **主题分类：**
   - 使用LLM对每个段落进行主题分类，识别演讲中的关键主题（如技术细节、案例分析、总结等）。
   - **工具：** 使用预训练的LLM模型（如GPT）进行段落分类，帮助将文本划分为不同的主题。

#### **目标：**
- 将转录文本拆分为多个易于处理的段落和主题块。
- 对演讲的内容进行分类，确保每个段落或块的语义清晰。

#### **输出：**
- 分段后的文本，每个段落或主题块带有标签和清晰的结构。

---

### **2025-05-03/04: 关键信息提取与实体识别**

#### **任务：**
1. **命名实体识别（NER）：**
   - 使用Llm等工具对文本进行命名实体识别，例如提取人名、组织名、地点等信息。
   - 使用LLM辅助分析，处理复杂的命名实体或需要上下文理解的情况。


#### **目标：**
- 提取出演讲中的命名实体、术语、项目等关键信息，并确保每个信息点都有明确标注。

#### **输出：**
- 提取出的关键信息列表，包括命名实体、技术术语、项目等，并附带上下文信息。

---

### **2025-05-05: 信息链接与总结生成**

#### **任务：**
1. **链接到维基百科与其他权威来源：**
   - 对提取的术语、命名实体和项目进行验证，并将其链接到维基百科等权威来源。
   - 使用wiki-api等接口 对于每个术语进行查询，获取相关信息和链接。

2. **生成演讲摘要：**
   - 使用LLM（如GPT）生成演讲的简洁摘要，突出关键信息和主要议题。
   - 将所有提取的信息整合成简洁、易读的报告。

3. **报告生成与格式化：**
   - 将所有提取的关键信息与相关链接整合成一个最终的报告，确保报告结构清晰，信息准确。
   - 根据需求，可以生成不同格式的报告（如PDF、Word、Markdown等）。

#### **目标：**
- 完成演讲的总结，并确保所有提取的术语、命名实体、项目等信息都已链接到权威资源。
- 完成最终报告的生成，并进行格式化输出。

#### **输出：**
- 完整的报告，包含演讲摘要、提取的关键信息以及相应的链接。


